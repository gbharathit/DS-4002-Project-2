---
title: "Project 2 MI3"
author: "Bharathi Thambidurai"
date: "2025-10-20"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This file focuses on taking our cleaned dataset and building a time series model for both average min and max temperatures

In MI2, we cleaned our data and stored the average minimum and maximum temperatures as time series objects in R. We also performed basic EDA to view how temperatures have changed over time, looking at specific months and looking at the overall trend. As we plotted our time series data, it was obvious there was a seasonal component we would have to keep in mind as we moved on to building a model.

```{r}
# from MI2!!
mintemp <- read.csv("C:\\Users\\gbhar\\OneDrive - University of Virginia\\ds 4002\\mean_min_monthly_temps_2000_2025.csv")
maxtemp <- read.csv("C:\\Users\\gbhar\\OneDrive - University of Virginia\\ds 4002\\mean_max_monthly_temps_2000_2025.csv")

mintemp_dat <- mintemp[mintemp$Year != c(2024,2025), ]
maxtemp_dat <- maxtemp[maxtemp$Year != c(2024,2025), ]

# order of months
month_levels <- c("Jan", "Feb", "Mar", "Apr", "May", "Jun", 
                  "Jul", "Aug", "Sep", "Oct", "Nov", "Dec")

# min temp reordered and stored as time series
mintemp_dat$Month <- factor(mintemp_dat$Month, levels = month_levels)
mintemp_sorted <- mintemp_dat[order(mintemp_dat$Year, mintemp_dat$Month), ]

mintemp_timeseries <- ts(mintemp_sorted$Mean_Min_Temp,frequency=12,start=c(2000,1))

# max temp reordered and stored as time series
maxtemp_dat$Month <- factor(maxtemp_dat$Month, levels = month_levels)
maxtemp_sorted <- maxtemp_dat[order(maxtemp_dat$Year, maxtemp_dat$Month), ]

maxtemp_timeseries <- ts(maxtemp_sorted$Value,frequency=12,start=c(2000,1))
```


We used <https://a-little-book-of-r-for-time-series.readthedocs.io/en/latest/src/timeseries.html> as a reference to guide us in our analysis.

# Minimum Average Temperatures

We first built a model using exponential smoothing. Due to the obvious seaonality, we opted to use Holt-Winters exponential smoothing. 
```{r}
# fit predictive model
mintempmodel <- HoltWinters(mintemp_timeseries)
mintempmodel # estimated values of alpha, beta, gamma
plot(mintempmodel) # plot model on top of existing data

library(forecast)

# forecasting
mintempforecast <- forecast(mintempmodel, h=12) # 12 more months (2024)
plot(mintempforecast) # plot our forecast values


# checking if there are any non-zero autocorrelations
acf(na.omit(mintempforecast$residuals), lag.max=20) # correlogram
Box.test(na.omit(mintempforecast$residuals), lag=20, type = "Ljung-Box") # Ljung-Box test
```

Fitting our model and forecasting for 2024 shows that the model does pick up on seasonality and follow existing trends. To check our accuracy, we can see in the correlogram that autocorrelations for forecast errors do not exceed significance bounds for almost all lags. The p-value for our Ljung-Box test is 0.95, further proving there is little evidence of non-zero autocorrelations at lags 1-20.

We can also check if forecast errors have constant variance over time and are normally distributed with mean zero.
```{r}
# from the guided tutorial we followed
plotForecastErrors <- function(forecasterrors)
  {
    forecasterrors <- na.omit(forecasterrors)
     # make a histogram of the forecast errors:
     mybinsize <- IQR(forecasterrors)/4
     mysd   <- sd(forecasterrors, na.rm=T)
     mymin  <- min(forecasterrors, na.rm=T) - mysd*5
     mymax  <- max(forecasterrors, na.rm=T) + mysd*3
     # generate normally distributed data with mean 0 and standard deviation mysd
     mynorm <- rnorm(10000, mean=0, sd=mysd)
     mymin2 <- min(mynorm)
     mymax2 <- max(mynorm)
     if (mymin2 < mymin) { mymin <- mymin2 }
     if (mymax2 > mymax) { mymax <- mymax2 }
     # make a red histogram of the forecast errors, with the normally distributed data overlaid:
     mybins <- seq(mymin, mymax, mybinsize)
     hist(forecasterrors, col="red", freq=FALSE, breaks=mybins)
     # freq=FALSE ensures the area under the histogram = 1
     # generate normally distributed data with mean 0 and standard deviation mysd
     myhist <- hist(mynorm, plot=FALSE, breaks=mybins)
     # plot the normal curve as a blue line on top of the histogram of forecast errors:
     points(myhist$mids, myhist$density, type="l", col="blue", lwd=2)
  }


plot.ts(mintempforecast$residuals)
plotForecastErrors(mintempforecast$residuals) # normally distributed with mean 0
```

From the time plot, we can see that the forecast errors have constant variance over time. From the histogram, we can also assume that forecast errors are normally distributed with mean zero.

**ARIMA MODEL**

While Holt-Winters exponential smoothing provides an adequate predictive model, we can make a better model by taking correlations in the data into account. We wanted to try making an ARIMA (Autoregressive Integrated Moving Average) model as well. 

Based on the tutorial and some trial-and-error in our model building, we realized our data needed to be differenced prior to determing what ARIMA parameters would best fit our model.

Once forcing a manual difference, we can use the auto.arima function to figure out the parameters of our ARIMA model.
```{r}
mintemp_arima <- auto.arima(
  mintemp_timeseries,
  d = 1,              # force one regular difference
  D = 1,              # seasonal difference (12-month)
  max.p = 5, max.q = 5,
  max.P = 2, max.Q = 2,
  stepwise = FALSE, approx = FALSE,
  trace = TRUE
)

mintemp_arima
```

Based on the auto.arima() function, we can determine that an ARIMA(0,1,1)x(2,1,0)[12] best fits our data. We can use this model to forecast for 2024. We want to check that this model meets all assumptions.
```{r}
mintempforecast2 <- forecast(mintemp_arima, h=12) # forecast using ARIMA model
mintempforecast2
plot(mintempforecast2) # add forecast values into time series plot

acf(mintempforecast2$residuals,lag.max=20) # correlogram
Box.test(mintempforecast2$residuals, lag=20, type="Ljung-Box") # Ljung-Box test
checkresiduals(mintemp_arima) # chceck that residuals are insignificant

plot.ts(mintempforecast2$residuals)
plotForecastErrors(mintempforecast2$residuals) # normally distributed with mean 0
```

Based on our model and forecast values, we see that the correlogram shows that barely any of the sample autocorrelations for lags 1-20 exceed significance bounds, the p-value of the Ljung-Box test is 0.81, and the p-value of our residuals is 0.31. We can conclude there is little evidence for non-zero autocorrelations in the forecast errors. 

From the time plot, we can see that the forecast errors have constant variance over time. From the histogram, we can also assume that forecast errors are normally distributed with mean zero.

Now, let's compare our forecast values from the ARIMA model to our actual values for 2024. 
```{r}
# extract 2024 from our data
mintemp_2024 <- mintemp[mintemp$Year==2024, ]
mintemp_2024
mintempforecast2
```

By comparing our forecast values of 2024 to our actual values of 2024, we can see that all the actual data falls in the 95% prediction interval for the forecast. Thus, we meet our goal of being at least 80% accurate with our model.

# Maximum Average Temperatures

We again built a model using exponential smoothing. Due to the obvious seaonality, we opted to use Holt-Winters exponential smoothing. 
```{r}
# fit predictive model
maxtempmodel <- HoltWinters(maxtemp_timeseries)
maxtempmodel # estimated values of alpha, beta, gamma
plot(maxtempmodel) # plot model on top of existing data


# forecasting
maxtempforecast <- forecast(maxtempmodel, h=12) # 12 more months (2024)
plot(maxtempforecast) # plot our forecast values


# checking if there are any non-zero autocorrelations
acf(na.omit(maxtempforecast$residuals), lag.max=20) # correlogram
Box.test(na.omit(maxtempforecast$residuals), lag=20, type = "Ljung-Box") # Ljung-Box test
```

Fitting our model and forecasting for 2024 shows that the model again does pick up on seasonality and follow existing trends. To check our accuracy, we can see in the correlogram that autocorrelations for forecast errors do not exceed significance bounds for all lags. The p-value for our Ljung-Box test is 0.80, further proving there is little evidence of non-zero autocorrelations at lags 1-20.

We can also check if forecast errors have constant variance over time and are normally distributed with mean zero.
```{r}
plot.ts(maxtempforecast$residuals)
plotForecastErrors(maxtempforecast$residuals) # normally distributed with mean 0
```

From the time plot, we can see that the forecast errors have constant variance over time. From the histogram, we can also assume that forecast errors are normally distributed with mean zero. Despite the curve being a bit wonky, it generally follows the normal distribution curve.

**ARIMA MODEL**

While Holt-Winters exponential smoothing provides an adequate predictive model, we again wanted to make a better model by taking correlations in the data into account. We wanted to try making an ARIMA (Autoregressive Integrated Moving Average) model for maximum average temperatures as well. 

Based on the tutorial and some trial-and-error in our model building, we again noticed our data needed to be differenced prior to determing what ARIMA parameters would best fit our model.

Once forcing a manual difference, we can use the auto.arima function to figure out the parameters of our ARIMA model.
```{r}
maxtemp_arima <- auto.arima(
  maxtemp_timeseries,
  d = 1,              # force one regular difference
  D = 1,              # seasonal difference (12-month)
  max.p = 5, max.q = 5,
  max.P = 2, max.Q = 2,
  stepwise = FALSE, approx = FALSE,
  trace = TRUE
)

maxtemp_arima
```

Based on the auto.arima() function, we can determine that an ARIMA(0,1,1)x(2,1,2)[12] best fits our data. We can use this model to forecast for 2024. We want to check that this model meets all assumptions.
```{r}
maxtempforecast2 <- forecast(maxtemp_arima, h=12) # forecast using ARIMA model
maxtempforecast2
plot(maxtempforecast2) # add forecast values into time series plot

acf(maxtempforecast2$residuals,lag.max=20) # correlogram
Box.test(maxtempforecast2$residuals, lag=20, type="Ljung-Box") # Ljung-Box test
checkresiduals(maxtemp_arima) # chceck that residuals are insignificant

plot.ts(maxtempforecast$residuals)
plotForecastErrors(maxtempforecast$residuals) # normally distributed with mean 0
```

Based on our model and forecast values, we see that the correlogram shows that barely any of the sample autocorrelations for lags 1-20 exceed significance bounds, the p-value of the Ljung-Box test is 0.84, and the p-value of our residuals is 0.62. We can conclude there is little evidence for non-zero autocorrelations in the forecast errors. 

From the time plot, we can see that the forecast errors have constant variance over time. From the histogram, we can also assume that forecast errors are normally distributed with mean zero.

Now, let's compare our forecast values from the ARIMA model to our actual values for 2024. 
```{r}
# extract 2024 from our data
maxtemp_2024 <- maxtemp[maxtemp$Year==2024, ]
maxtemp_2024
maxtempforecast2
```

By comparing our forecast values of 2024 to our actual values of 2024, we again can see that all the actual data falls in the 95% prediction interval for the forecast. Thus, we meet our goal of being at least 80% accurate with our model.

Using ARIMA models with differencing and a seasonality component allowed us to build accurate models which generated prediction intervals that managed to capture our actual data points.

